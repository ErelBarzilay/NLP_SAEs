{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNk7IylTv610"
      },
      "source": [
        "# Loading and Analysing Pre-Trained Sparse Autoencoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/joberant/NLP_2324b/erelbarzilay/conda_3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import sys \n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "sys.path.insert(0,\"/home/joberant/NLP_2324b/erelbarzilay/conda_3/envs/new_env/lib/python3.12/site-packages\")\n",
        "from datasets import load_dataset  \n",
        "from transformer_lens import HookedTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GPT2Tokenizer\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from utils import split_dataframe, get_frequency_df\n",
        "\n",
        "sys.path.insert(0,\"/vol/joberant_nobck/data/NLP_368307701_2324b/erelbarzilay/conda_3/envs/new_env/lib/python3.12/site-packages\")\n",
        "\n",
        "from sae_lens import SAE\n",
        "if torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoMx3VZpv611"
      },
      "source": [
        "# Loading a pretrained Sparse Autoencoder\n",
        "\n",
        "Below we load a Transformerlens model, a pretrained SAE and a dataset from huggingface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sNSfL80Uv611"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/joberant/NLP_2324b/erelbarzilay/conda_3/envs/new_env/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/vol/joberant_nobck/data/NLP_368307701_2324b/erelbarzilay/conda_3/envs/new_env/lib/python3.12/site-packages/sae_lens/sae.py:136: UserWarning: \n",
            "This SAE has non-empty model_from_pretrained_kwargs. \n",
            "For optimal performance, load the model like so:\n",
            "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset  \n",
        "from transformer_lens import HookedTransformer\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GPT2Tokenizer\n",
        "import sys\n",
        "sys.path.insert(0,\"/vol/joberant_nobck/data/NLP_368307701_2324b/erelbarzilay/conda_3/envs/new_env/lib/python3.12/site-packages\")\n",
        "\n",
        "from sae_lens import SAE\n",
        "device = \"cpu\" #Comment when have enough space\n",
        "model = HookedTransformer.from_pretrained(\"gpt2-small\", device = device)\n",
        "tokenizer = model.tokenizer\n",
        "# the cfg dict is returned alongside the SAE since it may contain useful information for analysing the SAE (eg: instantiating an activation store)\n",
        "# Note that this is not the same as the SAEs config dict, rather it is whatever was in the HF repo, from which we can extract the SAE config dict\n",
        "# We also return the feature sparsities which are stored in HF for convenience. \n",
        "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
        "    release = \"gpt2-small-res-jb\", # see other options in sae_lens/pretrained_saes.yaml\n",
        "    sae_id = \"blocks.0.hook_resid_pre\", # won't always be a hook point\n",
        "    device = device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[50256, 567, 75]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                               tokens         text  len  dict_val  enumerator\n",
            "0                   [13, 1828, 28139]  .22 caliber    3         1           0\n",
            "1              [13, 1828, 27417, 260]  .22 calibre    4         1           1\n",
            "2               [13, 1828, 12, 43288]  .22-caliber    4         1           2\n",
            "3      [13, 1828, 12, 9948, 571, 260]  .22-calibre    6         1           3\n",
            "4                   [13, 2548, 28139]  .38 caliber    3         2           4\n",
            "...                               ...          ...  ...       ...         ...\n",
            "40100                    [11195, 287]      home in    2      9236       40100\n",
            "40101                     [9521, 287]     range in    2      9236       40101\n",
            "40102                     [6603, 503]     pass out    2      9237       40102\n",
            "40103                    [13424, 503]    black out    2      9237       40103\n",
            "40104                [26361, 74, 503]     zonk out    3      9237       40104\n",
            "\n",
            "[40105 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from utils import split_dataframe\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "df = df[\"synonyms\"]\n",
        "# Preprocessing\n",
        "\n",
        "df = df.to_list()\n",
        "syn_dictionary = {}\n",
        "def gen():\n",
        "    new_df = []\n",
        "    i = 0\n",
        "    num = 0\n",
        "    for row in df:\n",
        "        i += 1\n",
        "        row = row[1:-1]\n",
        "        words = row.split(\",\")\n",
        "        for part in words:\n",
        "            word = part.split(\":\")[0]\n",
        "            word = word.strip()[1:-1]\n",
        "            new_df.append([tokenizer(word)[\"input_ids\"],word,len(tokenizer(word)[\"input_ids\"]), i, num])\n",
        "            num += 1\n",
        "    return new_df\n",
        "dataset = pd.DataFrame(gen())\n",
        "dataset.columns = [\"tokens\",\"text\", \"len\", \"dict_val\", \"enumerator\"]\n",
        "print(dataset)\n",
        "lst = []\n",
        "\n",
        "\n",
        "\n",
        "for i in range(1, 10):\n",
        "    lst.append([])\n",
        "    df_lst = split_dataframe(dataset[dataset[\"len\"] == i])\n",
        "    for df in df_lst:\n",
        "        lst[i - 1].append(Dataset.from_pandas(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy2uUl38v611"
      },
      "source": [
        "## Basic Analysis\n",
        "\n",
        "Let's check some basic stats on this SAE in order to see how some basic functionality in the codebase works.\n",
        "\n",
        "We'll calculate:\n",
        "- L0 (the number of features that fire per activation)\n",
        "- The cross entropy loss when the output of the SAE is used in place of the activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOcubgsRv611"
      },
      "source": [
        "### L0 Test and Reconstruction Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gAUR5CRBv611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 2, 768])\n",
            "torch.Size([1000, 2, 768])\n",
            "torch.Size([1000, 2, 768])\n",
            "torch.Size([1000, 2, 768])\n",
            "torch.Size([1000, 2, 768])\n",
            "torch.Size([937, 2, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([1000, 3, 768])\n",
            "torch.Size([782, 3, 768])\n",
            "torch.Size([1000, 4, 768])\n",
            "torch.Size([1000, 4, 768])\n",
            "torch.Size([1000, 4, 768])\n",
            "torch.Size([1000, 4, 768])\n",
            "torch.Size([1000, 4, 768])\n",
            "torch.Size([1000, 4, 768])\n",
            "torch.Size([1000, 4, 768])\n",
            "torch.Size([1000, 4, 768])\n",
            "torch.Size([1000, 4, 768])\n",
            "torch.Size([1000, 4, 768])\n",
            "torch.Size([1000, 4, 768])\n",
            "torch.Size([540, 4, 768])\n",
            "torch.Size([1000, 5, 768])\n",
            "torch.Size([1000, 5, 768])\n",
            "torch.Size([1000, 5, 768])\n",
            "torch.Size([77, 5, 768])\n",
            "torch.Size([607, 6, 768])\n",
            "torch.Size([120, 7, 768])\n",
            "torch.Size([28, 8, 768])\n",
            "torch.Size([11, 9, 768])\n",
            "torch.Size([3, 10, 768])\n"
          ]
        }
      ],
      "source": [
        "sae.eval()  # prevents error if we're expecting a dead neuron mask for who grads\n",
        "vals = []\n",
        "features = []\n",
        "sae_outs = []\n",
        "for i in range(1, 10):\n",
        "    vals.append([])\n",
        "    features.append([])\n",
        "    sae_outs.append([])\n",
        "    for df in lst[i - 1]:\n",
        "        with torch.no_grad():\n",
        "            # activation store can give us tokens.\n",
        "            batch_tokens = df[\"text\"]\n",
        "            _, cache = model.run_with_cache(batch_tokens, prepend_bos=True)\n",
        "\n",
        "            # Use the SAE\n",
        "            val = cache[sae.cfg.hook_name]\n",
        "            print(val.size())\n",
        "            vals[i - 1].append(val[:,i,:])\n",
        "            feature_acts = sae.encode(cache[sae.cfg.hook_name])\n",
        "            features[i - 1].append(feature_acts[:,i,:])\n",
        "            sae_out = sae.decode(feature_acts)\n",
        "            sae_outs[i - 1].append(sae_out[:,i,:])\n",
        "\n",
        "            # save some room\n",
        "            del cache\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def loss(x, x_hat):\n",
        "    return (x_hat - x).pow(2).sum(-1).sqrt()\n",
        "loss_lst = []\n",
        "rep_lst = []\n",
        "i = 0\n",
        "for lst_vals, lst_outs in zip(vals, sae_outs):\n",
        "    for value, out in zip(lst_vals, lst_outs):\n",
        "        app = loss(value, out)\n",
        "        print(app.size())\n",
        "        loss_lst.append(app)\n",
        "    rep_lst.append(torch.cat(features[i]))\n",
        "    i += 1\n",
        "rep_lst = torch.cat(rep_lst)\n",
        "result = torch.cat(loss_lst)\n",
        "result = result.detach().numpy()\n",
        "rep_lst = rep_lst.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset[\"loss\"] = result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open ('representation.pickle', 'wb') as f:\n",
        "    pickle.dump(rep_lst, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('representation.pickle', 'rb') as f:\n",
        "    representations = pickle.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_row_to_df(df, f, name):\n",
        "    add_col = []\n",
        "    for _, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
        "        add_col.append(f(representations[row[\"enum1\"]], representations[row[\"enum2\"]]))\n",
        "    syn_df[name] = add_col\n",
        "        \n",
        "add_row_to_df(syn_df, Jaccard_similarity, \"Jaccard_similarity\")\n",
        "\n",
        "add_row_to_df(syn_df, cosine_similarity, \"cosine_similarity\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_df = syn_df[syn_df[\"freq2\"] > 0]\n",
        "plt.scatter(syn_df[\"frequency_diff\"], syn_df[\"cosine_similarity\"])\n",
        "#plt.xscale(\"log\")\n",
        "import numpy as np\n",
        "z = np.polyfit(syn_df[\"frequency_diff\"], syn_df[\"cosine_similarity\"], 1)\n",
        "p = np.poly1d(z)\n",
        "plt.plot(syn_df[\"frequency_diff\"], p(syn_df[\"frequency_diff\"]), color = \"red\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijoelLtdv611"
      },
      "source": [
        "Note that while the mean L0 is 64, it varies with the specific activation.\n",
        "\n",
        "To estimate reconstruction performance, we calculate the CE loss of the model with and without the SAE being used in place of the activations. This will vary depending on the tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "fwrSvREJv612"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_TRq_lFv612"
      },
      "source": [
        "## Specific Capability Test\n",
        "\n",
        "Validating model performance on specific tasks when using the reconstructed activation is quite important when studying specific tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "npxKip_Qv612"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1swj9KA7v612"
      },
      "source": [
        "# Generating Feature Interfaces\n",
        "\n",
        "Feature dashboards are an important part of SAE Evaluation. They work by:\n",
        "- 1. Collecting feature activations over a larger number of examples.\n",
        "- 2. Aggregating feature specific statistics (such as max activating examples).\n",
        "- 3. Representing that information in a standardized way\n",
        "\n",
        "For our feature visualizations, we will use a separate library called SAEDashboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "edt8ag4fv612"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ94Frzbv612"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUaD6CFDv612"
      },
      "source": [
        "Now, since generating feature dashboards can be done once per sparse autoencoder, for pre-trained SAEs in the public domain, everyone can use the same dashboards. Neuronpedia hosts dashboards which we can load via the integration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxluyNRBv612"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import token_counter\n",
        "dataset[\"frequency\"] = token_counter.count_tokens_dataset(dataset, 60)\n",
        "dataset.to_csv(r\"frequencies_with_words.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(dataset[\"frequency\"], dataset[\"loss\"])\n",
        "import numpy as np\n",
        "z = np.polyfit(dataset[\"frequency\"], dataset[\"loss\"], 1)\n",
        "p = np.poly1d(z)\n",
        "plt.plot(dataset[\"frequency\"], p(dataset[\"frequency\"]), color = \"red\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_2 = dataset[dataset[\"frequency\"] > 0]\n",
        "quant = df_2[\"frequency\"].quantile(q = 0.05)\n",
        "\n",
        "df_2 = df_2[df_2[\"frequency\"] > quant]\n",
        "plt.scatter(df_2[\"frequency\"], df_2[\"loss\"])\n",
        "#plt.xscale(\"log\")\n",
        "import numpy as np\n",
        "z = np.polyfit(df_2[\"frequency\"], df_2[\"loss\"], 1)\n",
        "p = np.poly1d(z)\n",
        "plt.plot(df_2[\"frequency\"], p(df_2[\"frequency\"]), color = \"red\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def different(lst1, lst2):\n",
        "    if len(lst1) != len(lst2):\n",
        "        return True\n",
        "    else:\n",
        "        for i in range(len(lst1)):\n",
        "            if lst1[i] != lst2[i]:\n",
        "                return True\n",
        "    return False\n",
        "def add_interaction_column(dataset):\n",
        "    new_df = []\n",
        "    for _, entry in tqdm(dataset.iterrows(), total = dataset.shape[0]):\n",
        "        df_rel = dataset[dataset[\"dict_val\"] == entry[\"dict_val\"]]\n",
        "        for _, row in df_rel.iterrows():\n",
        "            if (row[\"frequency\"] > entry[\"frequency\"]) or (row[\"frequency\"] == entry[\"frequency\"] and row[\"text\"] > entry[\"text\"]):\n",
        "                if different(row[\"tokens\"], entry[\"tokens\"]):\n",
        "                    new_df.append([row[\"text\"], entry[\"text\"], row[\"frequency\"] - entry[\"frequency\"], row[\"frequency\"], entry[\"frequency\"], row[\"enumerator\"], entry[\"enumerator\"]])\n",
        "    new_df = pd.DataFrame(new_df)\n",
        "    new_df.columns = [\"text1\", \"text2\", \"frequency_diff\", \"freq1\", \"freq2\", \"enum1\", \"enum2\"]\n",
        "    return new_df\n",
        "def cosine_similarity(x_1, x_2):\n",
        "    x_1 = np.array(x_1)\n",
        "    x_2 = np.array(x_2)\n",
        "    return np.dot(x_1, x_2)/np.sqrt((np.dot(x_1, x_1) * np.dot(x_2, x_2)))\n",
        "\n",
        "def Jaccard_similarity(x_1, x_2):\n",
        "    x_1 = np.array(x_1)\n",
        "    x_2 = np.array(x_2)\n",
        "    intersection = np.sum(np.logical_and(x_1 != 0, x_2 != 0))\n",
        "    union = np.sum(np.logical_or(x_1 != 0, x_2 != 0))\n",
        "    return intersection/union\n",
        "\n",
        "syn_df = add_interaction_column(dataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
